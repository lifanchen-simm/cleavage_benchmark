{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "426c017b-94dc-460b-8c05-ce39153db12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ingo/micromamba/envs/affective/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from functools import partial\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "from tokenizers import ByteLevelBPETokenizer, BertWordPieceTokenizer\n",
    "from transformers import T5Tokenizer\n",
    "\n",
    "from loaders import CleavageLoader\n",
    "from denoise import NoiseAdaptation, CoteachingLoss, JoCoRLoss\n",
    "\n",
    "from models import (\n",
    "    BiLSTM, BiLSTMDivideMix,\n",
    "    BiLSTMPadded, BiLSTMPaddedDivideMix,\n",
    "    BiLSTMAttention, BiLSTMAttentionDivideMix,\n",
    "    BiLSTMProt2Vec, BiLSTMProt2VecDivideMix,\n",
    "    CNNAttention, CNNAttentionDivideMix,\n",
    "    MLP, MLPDivideMix,\n",
    "    ESM2BiLSTM, ESM2BiLSTMDivideMix,\n",
    "    ESM2, ESM2DivideMix,\n",
    "    T5BiLSTM, T5BiLSTMDivideMix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7879945-407b-47af-ab2a-daa7cf46401e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    with open(path, 'r') as csvfile:\n",
    "        train_data = list(csv.reader(csvfile))[1:] # skip col name\n",
    "        sents, lbls = [], []\n",
    "        for s, l in train_data:\n",
    "            sents.append(s)\n",
    "            lbls.append(l)\n",
    "    return sents, lbls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6697002c-986a-482e-9d9a-ef45418fc016",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = read_data('../data/c_train.csv')\n",
    "val_data = read_data('../data/c_val.csv')\n",
    "test_data = read_data('../data/c_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a09351a-79ba-459c-9553-b5c339804db8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0ce3ff-4b9b-41c6-8bd1-b373aaa6b939",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b531c305-3167-493b-b9e4-306c3db6b7b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e24645b-26bf-49fe-8835-6845c5686897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6437aa7d-3598-4b9a-bac9-78d5b374ada8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run tests for bbpm, wp, especially same performance on test set after reload, did correct fold/vocab get reloaded? - done\n",
    "# run test for some k-fold epochs - dnoe\n",
    "# run test for T5 with scaler stuff\n",
    "# run test with ESM\n",
    "# run tests with coteaching\n",
    "# run tests with coteaching plus\n",
    "# run tests with jocor\n",
    "# load prot2vec\n",
    "# run prot2vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf411aa-5322-4227-b136-8891555e12e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if denoising method is taken, add to naming path - done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b685b30-bae5-4c8d-bf57-1b701a537c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# which dtype are labels in NAD?\n",
    "#    should be .long()\n",
    "#    don't forget --nad flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedc4938-9937-496b-ad1e-734ec01b85f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c_bilstm3.cfg (with nad) had error that it trained with CEL, but it didn't to argmax\n",
    "\n",
    "\n",
    "# if we are running with NAD, we need to calculate argmax, not logits > 0\n",
    "# also need to calculate pos_pred then\n",
    "# then calculate roc_auc_score with pos_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedae1ad-cd44-4ea3-802a-b114bae25d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how we implemented loaders nad?\n",
    "# what does args.nad return? Is it a string or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2536dc7-1547-4e87-b48a-805fb0dc4590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the test loader to also have nad if nad is given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42539560-478d-4958-a8e4-45b1109c66c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when training coteaching:\n",
    "# run_epochs_coteach gets cot_criterion and criterion\n",
    "# but in training, criterion needs to be None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ab7ab4-4eee-4d5b-a918-1bf3593baed7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed659b3-1cfe-417c-a791-e814e9fc128d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make early-stopping epochs controllable via"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b4ec4b-cfd0-40d5-8f87-75e8aa86b11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP loads wrong model? why is there an embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd932e3-910c-4275-8b76-a5aa5e938a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optim with duplicate parameters? but only for ESM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fd18be-db8f-4da1-9fb4-d711e412d64b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f68e24-e27b-41c8-8ee5-79baa8ce6324",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d2c2715-7417-4e1a-9b10-c6864b9cc71f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Model tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2b7789-03f6-40a8-b49f-1f8333a2c419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_embeddings(path):\n",
    "    with open(path, 'r') as f:\n",
    "        seq, vec = [], []\n",
    "        for line in f.readlines()[2:]: # skip first special chars\n",
    "            lst = line.split()\n",
    "            seq.append(lst[0].upper())\n",
    "            vec.append([float(i) for i in lst[1:]])\n",
    "        vocab = {s: i for i, s in enumerate(seq)}\n",
    "        prot2vec = torch.tensor(vec, dtype=torch.float)\n",
    "    return vocab, prot2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3682b08-e60e-4eaf-afc6-66f6c85fd38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.randint(0, 20, (512, 10))\n",
    "x1_1 = torch.randint(0, 20, (512, 10))\n",
    "x2 = torch.randint(0, 20, (512, 10))\n",
    "x2_1 = torch.randint(0, 20, (512, 10))\n",
    "att = torch.ones_like(x1)\n",
    "lam = 0.6\n",
    "length = torch.arange(1, 513)\n",
    "lengths = torch.tensor([4, 5, 6, 7] * 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87326da6-47ba-40b7-bed7-31b9e659a628",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 20\n",
    "EMBEDDING_DIM = 128\n",
    "RNN_SIZE1 = 123\n",
    "RNN_SIZE2 = 222\n",
    "HIDDEN_SIZE = 100\n",
    "DROPOUT = 0.5\n",
    "OUT1 = 1\n",
    "OUT2 = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d30af5d-ae20-4cb4-ba1d-5e7fade84ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "bilstm = BiLSTM(VOCAB_SIZE, EMBEDDING_DIM, RNN_SIZE1, RNN_SIZE2, HIDDEN_SIZE, DROPOUT, OUT1)\n",
    "bilstmdividemix = BiLSTMDivideMix(VOCAB_SIZE, EMBEDDING_DIM, RNN_SIZE1, RNN_SIZE2, HIDDEN_SIZE, DROPOUT, OUT2)\n",
    "\n",
    "print(bilstm(x1).shape)\n",
    "print(bilstmdividemix(x1).shape)\n",
    "print(bilstmdividemix(x1, x2, lam, interpolate=True).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60c466b-77db-455a-b5d1-556ce24249f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bilstmpadded = BiLSTMPadded(VOCAB_SIZE, EMBEDDING_DIM, RNN_SIZE1, RNN_SIZE2, HIDDEN_SIZE, DROPOUT, OUT1, pad_idx=1)\n",
    "bilstmpaddeddividemix = BiLSTMPaddedDivideMix(VOCAB_SIZE, EMBEDDING_DIM, RNN_SIZE1, RNN_SIZE2, HIDDEN_SIZE, DROPOUT, OUT2, pad_idx=1)\n",
    "\n",
    "print(bilstmpadded(x1, lengths).shape)\n",
    "print(bilstmpaddeddividemix(x1, lengths).shape)\n",
    "print(bilstmpaddeddividemix(x1, lengths, x2, lengths, lam, interpolate=True).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10069327-0522-4817-8b29-c087b684ded1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bilstmattention = BiLSTMAttention(VOCAB_SIZE, EMBEDDING_DIM, RNN_SIZE1, HIDDEN_SIZE, 1, DROPOUT, OUT1)\n",
    "bilstmattentiondividemix = BiLSTMAttentionDivideMix(VOCAB_SIZE, EMBEDDING_DIM, RNN_SIZE1, HIDDEN_SIZE, 1, DROPOUT, OUT2)\n",
    "\n",
    "print(bilstmattention(x1).shape)\n",
    "print(bilstmattentiondividemix(x1).shape)\n",
    "print(bilstmattentiondividemix(x1, x2, lam, interpolate=True).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306109c2-2e8f-40e7-af40-485a098a1657",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, embeddings = read_embeddings(\"../params/uniref_3M.vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dce3cd-a618-4a96-a86d-8a5d1a793271",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = lambda seq: [vocab.get(s, 0) for s in seq.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7487cf3-5929-4cce-ac58-fb73e2081e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = CleavageLoader(train_data, val_data, test_data, tokenizer, 32, 4)\n",
    "train_loader, _, _ = loader.load(\"BiLSTM\", nad=False, unk_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef50d24-1e8c-4e04-a336-8dc8e4931f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq, lbl in train_loader:\n",
    "    seq1, lbl1 = seq, lbl\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e649801-afa0-4d93-b138-d524d10f38cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfa3f5f-77d9-44e4-86cb-6381a5e7dd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2201150e-c835-4183-93a6-c9b876d1b90e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bde15a7-7429-45f6-ad33-8eb523ecbbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bilstmprot2vec = BiLSTMProt2Vec(embeddings, RNN_SIZE1, HIDDEN_SIZE, DROPOUT, OUT1)\n",
    "bilstmprot2vecdividemix = BiLSTMProt2VecDivideMix(embeddings, RNN_SIZE1, HIDDEN_SIZE, DROPOUT, OUT2)\n",
    "\n",
    "print(bilstmprot2vec(x1).shape)\n",
    "print(bilstmprot2vecdividemix(x1, x2, lam, interpolate=True).shape)\n",
    "print(bilstmprot2vecdividemix(x1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf2312d-4192-4e22-8ad6-c05a1b4ec0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNNAttention(10, 2, 2, 4, 4, 5, 5, 2, 2, 10, 10, 1, 1, 23, 23, DROPOUT, OUT1)\n",
    "cnndividemix = CNNAttentionDivideMix(10, 2, 2, 4, 4, 5, 5, 2, 2, 10, 10, 1, 1, 23, 23, DROPOUT, OUT2)\n",
    "\n",
    "print(cnn(x1.float()).shape)\n",
    "print(cnndividemix(x1.float()).shape)\n",
    "print(cnndividemix(x1.float(), x2.float(), lam, interpolate=True).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f62d851-4d90-41c7-98f4-d898de993adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP(VOCAB_SIZE, 10, HIDDEN_SIZE, DROPOUT, OUT1)\n",
    "mlpdividemix = MLPDivideMix(VOCAB_SIZE, 10, HIDDEN_SIZE, DROPOUT, OUT2)\n",
    "\n",
    "print(mlp(torch.nn.functional.one_hot(x1).view(512, -1).float()).shape)\n",
    "print(mlpdividemix(torch.nn.functional.one_hot(x1).view(512, -1).float()).shape)\n",
    "print(mlpdividemix(torch.nn.functional.one_hot(x1).view(512, -1).float(), torch.nn.functional.one_hot(x2).view(512, -1).float(), lam, interpolate=True).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16c8bca-09bd-4700-9bd4-9dc8c31a3702",
   "metadata": {},
   "outputs": [],
   "source": [
    "esm2, vocab = torch.hub.load('facebookresearch/esm:main', 'esm2_t30_150M_UR50D')\n",
    "\n",
    "esm2bilstm = ESM2BiLSTM(esm2, RNN_SIZE1, HIDDEN_SIZE, DROPOUT, OUT1)\n",
    "esm2bilstmdividemix = ESM2BiLSTMDivideMix(esm2, RNN_SIZE1, HIDDEN_SIZE, DROPOUT, OUT2)\n",
    "\n",
    "print(esm2bilstm(x1).shape)\n",
    "print(esm2bilstmdividemix(x1).shape)\n",
    "print(esm2bilstmdividemix(x1, x2, lam, interpolate=True).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0005f8-017c-4d54-a411-05ee9e58d05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    esm2model = ESM2(esm2, DROPOUT, OUT1)\n",
    "    esm2dividemix = ESM2DivideMix(esm2, DROPOUT, OUT2)\n",
    "\n",
    "    print(esm2model(x1).shape)\n",
    "    print(esm2dividemix(x1).shape)\n",
    "    print(esm2dividemix(x1, x2, lam, interpolate=True).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ce3c2b-8dd9-4555-8a47-8ecbb908c3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5 = T5BiLSTM(RNN_SIZE1, HIDDEN_SIZE, DROPOUT, OUT1).cuda()\n",
    "t5dividemix = T5BiLSTMDivideMix(RNN_SIZE1, HIDDEN_SIZE, DROPOUT, OUT2).cuda()\n",
    "\n",
    "print(t5(x1.long().cuda(), att.cuda()).shape)\n",
    "print(t5dividemix(x1.long().cuda(), att.cuda()).shape)\n",
    "print(t5dividemix(x1.long().cuda(), att.cuda(), x2.long().cuda(), att.cuda(), lam, interpolate=True).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9becad01-82d5-4645-be83-375a55195900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de315ae6-8119-41b2-b0b9-48c35a414a1b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add4ae63-7e75-4cf0-a4b2-920ac5a41d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoiseAdaptation(nn.Module):\n",
    "    def __init__(self, theta, k):\n",
    "        super().__init__()\n",
    "        self.theta = nn.Linear(k, k, bias=False)\n",
    "        self.theta.weight.data = theta\n",
    "        self.eye = torch.eye(k)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        theta = self.theta(self.eye)\n",
    "        theta = torch.softmax(theta, dim=0)\n",
    "        out = x @ theta\n",
    "        return out\n",
    "    \n",
    "class NoiseAdaptation2(nn.Module):\n",
    "    def __init__(self, theta, k):\n",
    "        super().__init__()\n",
    "        self.theta = nn.Linear(k, k, bias=False)\n",
    "        self.theta.weight.data = theta\n",
    "        self.eye = torch.eye(k)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        theta = self.theta(self.eye)\n",
    "        theta = torch.softmax(theta, dim=0)\n",
    "        out = torch.matmul(x, theta)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b92e07-45f9-448d-ba9f-b1d3901a6c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = torch.randn(2, 2)\n",
    "theta = theta / theta.sum(dim=1, keepdim=True)\n",
    "nad = NoiseAdaptation(theta, 2)\n",
    "nad2 = NoiseAdaptation2(theta, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bfa0f3-f52c-4e92-8856-86f9180aea90",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(512, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84af6e6-32c7-4339-afee-3dc4a4e143f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nad(x) == nad2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b3900c-73ba-4148-b5b5-b0aacb6814ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def loss_coteaching(y_1, y_2, t, forget_rate):\n",
    "    criterion = nn.BCEWithLogitsLoss(reduction='none')\n",
    "    \n",
    "    loss_1 = criterion(y_1, t)\n",
    "    ind_1_sorted = np.argsort(loss_1.data.cpu())\n",
    "    loss_1_sorted = loss_1[ind_1_sorted]\n",
    "\n",
    "    loss_2 = criterion(y_2, t)\n",
    "    ind_2_sorted = np.argsort(loss_2.data.cpu())\n",
    "    loss_2_sorted = loss_2[ind_2_sorted]\n",
    "\n",
    "    remember_rate = 1 - forget_rate\n",
    "    num_remember = int(remember_rate * len(loss_1_sorted))\n",
    "\n",
    "    ind_1_update = ind_1_sorted[:num_remember]\n",
    "    ind_2_update = ind_2_sorted[:num_remember]\n",
    "    \n",
    "    # exchange\n",
    "    loss_1_update = criterion(y_1[ind_2_update], t[ind_2_update])\n",
    "    loss_2_update = criterion(y_2[ind_1_update], t[ind_1_update])\n",
    "\n",
    "    return torch.sum(loss_1_update)/num_remember, torch.sum(loss_2_update)/num_remember\n",
    "\n",
    "\n",
    "class CoteachingLoss:\n",
    "    def __init__(self):\n",
    "        self.criterion = nn.BCEWithLogitsLoss(reduction='none')\n",
    "\n",
    "    def __call__(self, y1, y2, t, forget_rate):\n",
    "        l1 = self.criterion(y1, t)\n",
    "        idx1 = torch.argsort(l1)\n",
    "\n",
    "        l2 = self.criterion(y2, t)\n",
    "        idx2 = torch.argsort(l2)\n",
    "\n",
    "        remember_rate = 1 - forget_rate\n",
    "        num_remember = int(remember_rate * l1.shape[0])\n",
    "\n",
    "        idx1_update = idx1[:num_remember]\n",
    "        idx2_update = idx2[:num_remember]\n",
    "\n",
    "        # exchange the samples\n",
    "        l1_update = self.criterion(y1[idx2_update], t[idx2_update])\n",
    "        l2_update = self.criterion(y2[idx1_update], t[idx1_update])\n",
    "\n",
    "        return l1_update.sum() / num_remember, l2_update.sum() / num_remember\n",
    "\n",
    "\n",
    "cot = CoteachingLoss()\n",
    "\n",
    "y1 = torch.randn(512)\n",
    "y2 = torch.randn(512)\n",
    "t = torch.randint(0, 2, (512,))\n",
    "fgt = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee141ac9-e5c2-4e99-a9b0-4ac78d9b7fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = loss_coteaching(y1, y2, t.float(), fgt)\n",
    "b = cot(y1, y2, t.float(), fgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1b60b8-a985-4db2-bd8a-e0deef233afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl(pred, lbl):\n",
    "    return F.kl_div(F.logsigmoid(pred), F.sigmoid(lbl), reduction='sum')\n",
    "\n",
    "def kl2(pred, lbl):\n",
    "    return torch.sum(F.kl_div(F.logsigmoid(pred), F.sigmoid(lbl), reduction='none'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef0b787-2f00-49bc-9a45-0de61d50a2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "kl(y1, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd04729c-383a-47e2-a23d-6cc36315bd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kl2(y1, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28506906-6499-44bd-89ed-a4175e595790",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JoCoRLoss:\n",
    "    \"\"\"\n",
    "    Based on:\n",
    "\n",
    "    Wei, H., Feng, L., Chen, X., & An, B. (2020).\n",
    "    Combating noisy labels by agreement: A joint training method with co-regularization.\n",
    "    In Proceedings of the IEEE/CVF conference on\n",
    "    computer vision and pattern recognition (pp. 13726-13735).\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.criterion = nn.BCEWithLogitsLoss(reduction='none')\n",
    "        self.co_lambda = 0.1\n",
    "\n",
    "    def kl_loss(self, pred, soft_target):\n",
    "        return F.kl_div(F.logsigmoid(pred), F.sigmoid(soft_target), reduction='sum') \n",
    "\n",
    "    def __call__(self, y1, y2, lbls, forget_rate):\n",
    "        l1 = self.criterion(y1, lbls) * (1 - self.co_lambda)\n",
    "        l2 = self.criterion(y2, lbls) * (1 - self.co_lambda)\n",
    "        losses = l1 + l2 + (self.co_lambda * self.kl_loss(y1, y2)) + (self.co_lambda * self.kl_loss(y2, y1))\n",
    "\n",
    "        idx = torch.argsort(losses)\n",
    "        remember_rate = 1 - forget_rate\n",
    "        num_remember = int(remember_rate * losses.shape[0])\n",
    "\n",
    "        idx_update = idx[:num_remember]\n",
    "        loss = losses[idx_update].mean()\n",
    "        return loss, loss\n",
    "    \n",
    "def kl_loss_compute(pred, soft_targets):\n",
    "    # adjusted for binary case\n",
    "    kl = F.kl_div(F.logsigmoid(pred), torch.sigmoid(soft_targets), reduction='none')\n",
    "    return torch.sum(kl)\n",
    "\n",
    "\n",
    "class JoCoRLoss2:\n",
    "    def __call__(self, y1, y2, lbls, forget_rate, loss_func, kl_loss, co_lambda=0.1):\n",
    "        loss_pick_1 = loss_func(y1, lbls) * (1 - co_lambda)\n",
    "        loss_pick_2 = loss_func(y2, lbls) * (1 - co_lambda)\n",
    "        loss_pick = (\n",
    "            loss_pick_1\n",
    "            + loss_pick_2\n",
    "            + co_lambda * kl_loss_compute(y1, y2)\n",
    "            + co_lambda * kl_loss_compute(y2, y1)\n",
    "        ).cpu()\n",
    "\n",
    "        ind_sorted = np.argsort(loss_pick.data)\n",
    "        loss_sorted = loss_pick[ind_sorted]\n",
    "\n",
    "        remember_rate = 1 - forget_rate\n",
    "        num_remember = int(remember_rate * len(loss_sorted))\n",
    "\n",
    "        ind_update = ind_sorted[:num_remember]\n",
    "\n",
    "        loss = torch.mean(loss_pick[ind_update])\n",
    "\n",
    "        return loss, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b483974e-7328-428d-864c-e52b4a404aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "jocor = JoCoRLoss()\n",
    "jocor2 = JoCoRLoss2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a5ae6a-2d3c-43d3-854a-3dfa7767b9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = jocor(y1, y2, t.float(), 0.2)\n",
    "b = jocor2(y1, y2, t.float(), 0.2, nn.BCEWithLogitsLoss(reduction='none'), kl_loss_compute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e256fc6f-d516-4429-9b02-84bc73c545c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639a7b69-bc33-4f42-930e-951e037914e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dac1dd-9df1-4085-9368-ea73a8b5fb07",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Collators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19542ba4-e523-492b-b541-778093ac5822",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_random_masking(seq, unk_idx):\n",
    "    \"\"\"\n",
    "    Mask `seq_len // 10` tokens as UNK at random positions per sequence. \n",
    "    \"\"\"\n",
    "    num_samples, seq_len = seq.shape\n",
    "    mask_idx = torch.randint(0, seq_len, (num_samples, seq_len // 10))\n",
    "    masked_seq = torch.scatter(seq, 1, mask_idx, unk_idx)\n",
    "    return masked_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d9a965-7152-4d86-b881-d640a9d2b5b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CollateFunctions:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def collate_fn(self, model_name: str, denoising_method: str, training_mode: str) -> Callable:\n",
    "        if model_name == \"model1\":\n",
    "            return functools.partial(self._collate_model1, denoising_method, training_mode)\n",
    "        elif model_name == \"model2\":\n",
    "            return functools.partial(self._collate_model2, denoising_method, training_mode)\n",
    "        elif model_name == \"model3\":\n",
    "            return functools.partial(self._collate_model3, denoising_method, training_mode)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model name: {model_name}\")\n",
    "\n",
    "    def _collate_model1(self, denoising_method: str, training_mode: str, batch) -> Any:\n",
    "        # Collation logic for model1\n",
    "        # Use denoising_method and training_mode as needed\n",
    "        ...\n",
    "\n",
    "    def _collate_model2(self, denoising_method: str, training_mode: str, batch) -> Any:\n",
    "        # Collation logic for model2\n",
    "        # Use denoising_method and training_mode as needed\n",
    "        ...\n",
    "\n",
    "    def _collate_model3(self, denoising_method: str, training_mode: str, batch) -> Any:\n",
    "        # Collation logic for model3\n",
    "        # Use denoising_method and training_mode as needed\n",
    "        ...\n",
    "\n",
    "# Usage example:\n",
    "collate_fns = CollateFunctions()\n",
    "model_name = \"model1\"\n",
    "denoising_method = \"denoise1\"\n",
    "training_mode = \"train\"\n",
    "\n",
    "# Generate the collate function\n",
    "collate_fn = collate_fns.collate_fn(model_name, denoising_method, training_mode)\n",
    "\n",
    "# Use the collate function in a DataLoader\n",
    "data_loader = DataLoader(dataset, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4df658-c67b-4674-85e8-bcb6cf54208f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_batch(batch, mode):\n",
    "    ordered_batch = list(zip(*batch))\n",
    "    seq = torch.tensor([encode_text(seq) for seq in ordered_batch[0]], dtype=torch.int64)\n",
    "    lbl = torch.tensor([int(l) for l in ordered_batch[1]], dtype=torch.float)\n",
    "    \n",
    "    if mode == 'train':\n",
    "        seq = apply_random_masking(seq, unk_idx=0)\n",
    "\n",
    "    return seq, lbl\n",
    "\n",
    "# Create a partial function with additional arguments\n",
    "collate_fn_train = partial(collate_batch, mode='train')\n",
    "collate_fn_test = partial(collate_batch, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29ad224-79f9-4aa2-aa5f-caeb648f6315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    with open(path, 'r') as csvfile:\n",
    "        train_data = list(csv.reader(csvfile))[1:] # skip col name\n",
    "        sents, lbls = [], []\n",
    "        for s, l in train_data:\n",
    "            sents.append(s)\n",
    "            lbls.append(l)\n",
    "    return sents, lbls\n",
    "\n",
    "train_seq, train_lbl = read_data('../data/c_train.csv')\n",
    "\n",
    "\n",
    "class CleavageDataset(Dataset):\n",
    "    def __init__(self, seq, lbl):\n",
    "        self.seq = seq\n",
    "        self.lbl = lbl\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.seq[idx], self.lbl[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.lbl)\n",
    "    \n",
    "train_data = CleavageDataset(train_seq, train_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40de1347-739c-4dde-aee8-f79e46ee3f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create vocab from train seqs\n",
    "vocab_base = build_vocab_from_iterator(train_seq, specials=['<UNK>'])\n",
    "# vocab = build_vocab_from_iterator(train_seqs)\n",
    "vocab_base.set_default_index(vocab_base['<UNK>'])\n",
    "encode_text = lambda x: vocab_base(list(x))\n",
    "\n",
    "# load pre-trained esm2 model and vocab\n",
    "esm2, vocab = torch.hub.load('facebookresearch/esm:main', 'esm2_t30_150M_UR50D')\n",
    "tokenizer_esm = vocab.get_batch_converter()\n",
    "\n",
    "tokenizer_t5 = T5Tokenizer.from_pretrained(\n",
    "    \"Rostlab/prot_t5_xl_half_uniref50-enc\", do_lower_case=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9f82e2-a2e7-4e17-a701-e33d0c14d5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all tokenizers here\n",
    "bbpe1_vocab, bbpe1_merges = '../params/c_bbpe1k-vocab.json', '../params/c_bbpe1k-merges.txt'\n",
    "bbpe50_vocab, bbpe50_merges = '../params/c_bbpe50k-vocab.json', '../params/c_bbpe50k-merges.txt'\n",
    "wp50_vocab = '../params/c_wp50k-vocab.txt'\n",
    "\n",
    "bbpe1 = ByteLevelBPETokenizer.from_file(bbpe1_vocab, bbpe1_merges, lowercase=False)\n",
    "bbpe1.enable_padding(pad_id=1, pad_token='<PAD>')\n",
    "\n",
    "bbpe50 = ByteLevelBPETokenizer.from_file(bbpe50_vocab, bbpe50_merges, lowercase=False)\n",
    "bbpe50.enable_padding(pad_id=1, pad_token='<PAD>')\n",
    "\n",
    "wp50 = BertWordPieceTokenizer(wp50_vocab)\n",
    "wp50.enable_padding(pad_id=0, pad_token='[PAD]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9512817b-5f9e-4955-89f3-ba353ab47c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test all functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd05b91-dcda-42d2-a6d7-6ded59582d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loaders import BatchCollator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25334ef-5ec7-46dd-bbe3-9ae195f0f774",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_collator = BatchCollator(encode_text)\n",
    "esm2_collator = BatchCollator(tokenizer_esm)\n",
    "t5_collator = BatchCollator(tokenizer_t5)\n",
    "bbpe1_collator = BatchCollator(bbpe1)\n",
    "bbpe50_collator = BatchCollator(bbpe50)\n",
    "wp50_collator = BatchCollator(wp50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517df757-0d93-4a4c-b6ef-a66363f437ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# works for BiLSTM, BiLSTMAttentino, BiLSTMProt2Vec\n",
    "base_train = base_collator.collate_fn('BiLSTM', nad=False, train=True, unk_idx=0)\n",
    "base_test = base_collator.collate_fn('BiLSTMAttention', nad=False, train=False, unk_idx=0)\n",
    "base_train_nad = base_collator.collate_fn('BiLSTM', nad=True, train=True, unk_idx=0)\n",
    "base_test_nad = base_collator.collate_fn('BiLSTMProt2Vec', nad=True, train=False, unk_idx=0)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=16, collate_fn=base_train, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(train_data, batch_size=16, collate_fn=base_test, num_workers=4)\n",
    "train_loader_nad = torch.utils.data.DataLoader(train_data, batch_size=16, collate_fn=base_train_nad, num_workers=4)\n",
    "test_loader_nad = torch.utils.data.DataLoader(train_data, batch_size=16, collate_fn=base_test_nad, num_workers=4)\n",
    "\n",
    "for seq, lbl in train_loader:\n",
    "    seq1, lbl1 = seq, lbl\n",
    "    break\n",
    "    \n",
    "for seq, lbl in test_loader:\n",
    "    seq2, lbl2 = seq, lbl\n",
    "    break\n",
    "    \n",
    "for seq, lbl in train_loader_nad:\n",
    "    seq1_nad, lbl1_nad = seq, lbl\n",
    "    break\n",
    "    \n",
    "for seq, lbl in test_loader_nad:\n",
    "    seq2_nad, lbl2_nad = seq, lbl\n",
    "    break   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fc4c66-bcc7-48f7-b786-1b2e427d1213",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert seq1.dtype == torch.int64, \"wrong sequence dtype\"\n",
    "assert all([0 in s[n] for s in [seq1, seq1_nad] for n in range(s.shape[0])]), \"masking didn't work\"\n",
    "assert not all([0 in s[n] for s in [seq2, seq2_nad] for n in range(s.shape[0])]), \"masking found in test set\"\n",
    "assert lbl1.dtype == torch.float32, \"wrong lbl dtype\"\n",
    "assert (lbl1 == lbl2).sum() == lbl1.shape[0], \"lbl1 and lbl2 are not equal\"\n",
    "assert (lbl1_nad == lbl2_nad).sum() == lbl1.shape[0], \"lbl1_nad and lbl2_nad are not equal\"\n",
    "assert lbl2_nad.dtype == torch.int64, \"nad lbl dtype wrong\"\n",
    "assert lbl1_nad.dtype == torch.int64, \"nad llb dtype wrong\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e5e6b9-6868-44d2-984b-3637c1b93be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# works for CNN\n",
    "cnn_train = base_collator.collate_fn('CNN', nad=False, train=True, unk_idx=0)\n",
    "cnn_test = base_collator.collate_fn('CNN', nad=False, train=False, unk_idx=0)\n",
    "cnn_train_nad = base_collator.collate_fn('CNN', nad=True, train=True, unk_idx=0)\n",
    "cnn_test_nad = base_collator.collate_fn('CNN', nad=True, train=False, unk_idx=0)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=16, collate_fn=cnn_train, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(train_data, batch_size=16, collate_fn=cnn_test, num_workers=4)\n",
    "train_loader_nad = torch.utils.data.DataLoader(train_data, batch_size=16, collate_fn=cnn_train_nad, num_workers=4)\n",
    "test_loader_nad = torch.utils.data.DataLoader(train_data, batch_size=16, collate_fn=cnn_test_nad, num_workers=4)\n",
    "\n",
    "for seq, lbl in train_loader:\n",
    "    seq1, lbl1 = seq, lbl\n",
    "    break\n",
    "    \n",
    "for seq, lbl in test_loader:\n",
    "    seq2, lbl2 = seq, lbl\n",
    "    break\n",
    "    \n",
    "for seq, lbl in train_loader_nad:\n",
    "    seq1_nad, lbl1_nad = seq, lbl\n",
    "    break\n",
    "    \n",
    "for seq, lbl in test_loader_nad:\n",
    "    seq2_nad, lbl2_nad = seq, lbl\n",
    "    break   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5919c8-c39b-45ec-8a13-07ee4b26e13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert seq1.dtype == torch.float32, \"wrong sequence dtype\"\n",
    "assert all([0 in s[n] for s in [seq1, seq1_nad] for n in range(s.shape[0])]), \"masking didn't work\"\n",
    "assert not all([0 in s[n] for s in [seq2, seq2_nad] for n in range(s.shape[0])]), \"masking found in test set\"\n",
    "assert lbl1.dtype == torch.float32, \"wrong lbl dtype\"\n",
    "assert (lbl1 == lbl2).sum() == lbl1.shape[0], \"lbl1 and lbl2 are not equal\"\n",
    "assert (lbl1_nad == lbl2_nad).sum() == lbl1.shape[0], \"lbl1_nad and lbl2_nad are not equal\"\n",
    "assert lbl2_nad.dtype == torch.int64, \"nad lbl dtype wrong\"\n",
    "assert lbl1_nad.dtype == torch.int64, \"nad llb dtype wrong\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f953da60-10bc-4087-88ac-98dad213056a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# works for MLP\n",
    "mlp_train = base_collator.collate_fn('MLP', nad=False, train=True, unk_idx=0)\n",
    "mlp_test = base_collator.collate_fn('MLP', nad=False, train=False, unk_idx=0)\n",
    "mlp_train_nad = base_collator.collate_fn('MLP', nad=True, train=True, unk_idx=0)\n",
    "mlp_test_nad = base_collator.collate_fn('MLP', nad=True, train=False, unk_idx=0)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=16, collate_fn=mlp_train, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(train_data, batch_size=16, collate_fn=mlp_test, num_workers=4)\n",
    "train_loader_nad = torch.utils.data.DataLoader(train_data, batch_size=16, collate_fn=mlp_train_nad, num_workers=4)\n",
    "test_loader_nad = torch.utils.data.DataLoader(train_data, batch_size=16, collate_fn=mlp_test_nad, num_workers=4)\n",
    "\n",
    "for seq, lbl in train_loader:\n",
    "    seq1, lbl1 = seq, lbl\n",
    "    break\n",
    "    \n",
    "for seq, lbl in test_loader:\n",
    "    seq2, lbl2 = seq, lbl\n",
    "    break\n",
    "    \n",
    "for seq, lbl in train_loader_nad:\n",
    "    seq1_nad, lbl1_nad = seq, lbl\n",
    "    break\n",
    "    \n",
    "for seq, lbl in test_loader_nad:\n",
    "    seq2_nad, lbl2_nad = seq, lbl\n",
    "    break   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27c4b86-57f8-413a-bbd7-291336b9995f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert seq1.dtype == torch.float32, \"wrong sequence dtype\"\n",
    "assert sum([\n",
    "    s[sample][n][0] == 1\n",
    "    for s in [seq1, seq1_nad]\n",
    "    for sample in range(s.shape[0])\n",
    "    for n in range(s.shape[1])\n",
    "]) == 32, \"masking didn't work\"\n",
    "assert sum([\n",
    "    s[sample][n][0] == 1\n",
    "    for s in [seq2, seq2_nad]\n",
    "    for sample in range(s.shape[0])\n",
    "    for n in range(s.shape[1])\n",
    "]) == 0, \"mask found in test batch\"\n",
    "assert seq1.sum() == seq2.sum(), \"different UNK/data strucutre\"\n",
    "assert lbl1.dtype == torch.float32, \"wrong lbl dtype\"\n",
    "assert (lbl1 == lbl2).sum() == lbl1.shape[0], \"lbl1 and lbl2 are not equal\"\n",
    "assert (lbl1_nad == lbl2_nad).sum() == lbl1.shape[0], \"lbl1_nad and lbl2_nad are not equal\"\n",
    "assert lbl2_nad.dtype == torch.int64, \"nad lbl dtype wrong\"\n",
    "assert lbl1_nad.dtype == torch.int64, \"nad llb dtype wrong\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e26f6a6-0377-4d79-a621-0c1ab246bc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# works for BBP1\n",
    "bbpe1_train = bbpe1_collator.collate_fn('BiLSTMPadded', nad=False, train=True, unk_idx=0)\n",
    "bbpe1_test = bbpe1_collator.collate_fn('BiLSTMPadded', nad=False, train=False, unk_idx=0)\n",
    "bbpe1_train_nad = bbpe1_collator.collate_fn('BiLSTMPadded', nad=True, train=True, unk_idx=0)\n",
    "bbpe1_test_nad = bbpe1_collator.collate_fn('BiLSTMPadded', nad=True, train=False, unk_idx=0)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=16, collate_fn=bbpe1_train, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(train_data, batch_size=16, collate_fn=bbpe1_test, num_workers=4)\n",
    "train_loader_nad = torch.utils.data.DataLoader(train_data, batch_size=16, collate_fn=bbpe1_train_nad, num_workers=4)\n",
    "test_loader_nad = torch.utils.data.DataLoader(train_data, batch_size=16, collate_fn=bbpe1_test_nad, num_workers=4)\n",
    "\n",
    "for seq, lbl, lengths in train_loader:\n",
    "    seq1, lbl1, lengths1 = seq, lbl, lengths\n",
    "    break\n",
    "    \n",
    "for seq, lbl, lengths in test_loader:\n",
    "    seq2, lbl2, lengths2 = seq, lbl, lengths\n",
    "    break\n",
    "    \n",
    "for seq, lbl, lengths in train_loader_nad:\n",
    "    seq1_nad, lbl1_nad, lengths_nad = seq, lbl, lengths\n",
    "    break\n",
    "    \n",
    "for seq, lbl, lengths in test_loader_nad:\n",
    "    seq2_nad, lbl2_nad, lengths2_nad = seq, lbl, lengths\n",
    "    break   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a709667-7706-4157-b760-7e733a5414e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert seq1.dtype == torch.int64, \"wrong sequence dtype\"\n",
    "assert lengths1.dtype == torch.int64, \"wrong lenghts dtype\"\n",
    "assert seq1.sum() == seq2.sum(), \"different UNK/data strucutre\"\n",
    "assert lbl1.dtype == torch.float32, \"wrong lbl dtype\"\n",
    "assert (lbl1 == lbl2).sum() == lbl1.shape[0], \"lbl1 and lbl2 are not equal\"\n",
    "assert (lbl1_nad == lbl2_nad).sum() == lbl1.shape[0], \"lbl1_nad and lbl2_nad are not equal\"\n",
    "assert lbl2_nad.dtype == torch.int64, \"nad lbl dtype wrong\"\n",
    "assert lbl1_nad.dtype == torch.int64, \"nad llb dtype wrong\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3989f7b0-1d87-4e33-8142-f66d9da685f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# works for BBPE50\n",
    "bbpe50_train = bbpe50_collator.collate_fn('BiLSTMPadded', nad=False, train=True, unk_idx=0)\n",
    "bbpe50_test = bbpe50_collator.collate_fn('BiLSTMPadded', nad=False, train=False, unk_idx=0)\n",
    "bbpe50_train_nad = bbpe50_collator.collate_fn('BiLSTMPadded', nad=True, train=True, unk_idx=0)\n",
    "bbpe50_test_nad = bbpe50_collator.collate_fn('BiLSTMPadded', nad=True, train=False, unk_idx=0)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=16, collate_fn=bbpe50_train, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(train_data, batch_size=16, collate_fn=bbpe50_test, num_workers=4)\n",
    "train_loader_nad = torch.utils.data.DataLoader(train_data, batch_size=16, collate_fn=bbpe50_train_nad, num_workers=4)\n",
    "test_loader_nad = torch.utils.data.DataLoader(train_data, batch_size=16, collate_fn=bbpe50_test_nad, num_workers=4)\n",
    "\n",
    "for seq, lbl, lengths in train_loader:\n",
    "    seq1, lbl1, lengths1 = seq, lbl, lengths\n",
    "    break\n",
    "    \n",
    "for seq, lbl, lengths in test_loader:\n",
    "    seq2, lbl2, lengths2 = seq, lbl, lengths\n",
    "    break\n",
    "    \n",
    "for seq, lbl, lengths in train_loader_nad:\n",
    "    seq1_nad, lbl1_nad, lengths_nad = seq, lbl, lengths\n",
    "    break\n",
    "    \n",
    "for seq, lbl, lengths in test_loader_nad:\n",
    "    seq2_nad, lbl2_nad, lengths2_nad = seq, lbl, lengths\n",
    "    break   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ceb9ec6-fc5f-4412-9e9f-7b59c777dd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert seq1.dtype == torch.int64, \"wrong sequence dtype\"\n",
    "assert lengths1.dtype == torch.int64, \"wrong lenghts dtype\"\n",
    "assert seq1.sum() == seq2.sum(), \"different UNK/data strucutre\"\n",
    "assert lbl1.dtype == torch.float32, \"wrong lbl dtype\"\n",
    "assert (lbl1 == lbl2).sum() == lbl1.shape[0], \"lbl1 and lbl2 are not equal\"\n",
    "assert (lbl1_nad == lbl2_nad).sum() == lbl1.shape[0], \"lbl1_nad and lbl2_nad are not equal\"\n",
    "assert lbl2_nad.dtype == torch.int64, \"nad lbl dtype wrong\"\n",
    "assert lbl1_nad.dtype == torch.int64, \"nad llb dtype wrong\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e6a006-7224-45c1-8ac1-a0fd2a4582ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# works for WP\n",
    "wp_train = wp50_collator.collate_fn('BiLSTMPadded', nad=False, train=True, unk_idx=1)\n",
    "wp_test = wp50_collator.collate_fn('BiLSTMPadded', nad=False, train=False, unk_idx=1)\n",
    "wp_train_nad = wp50_collator.collate_fn('BiLSTMPadded', nad=True, train=True, unk_idx=1)\n",
    "wp_test_nad = wp50_collator.collate_fn('BiLSTMPadded', nad=True, train=False, unk_idx=1)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=16, collate_fn=wp_train, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(train_data, batch_size=16, collate_fn=wp_test, num_workers=4)\n",
    "train_loader_nad = torch.utils.data.DataLoader(train_data, batch_size=16, collate_fn=wp_train_nad, num_workers=4)\n",
    "test_loader_nad = torch.utils.data.DataLoader(train_data, batch_size=16, collate_fn=wp_test_nad, num_workers=4)\n",
    "\n",
    "for seq, lbl, lengths in train_loader:\n",
    "    seq1, lbl1, lengths1 = seq, lbl, lengths\n",
    "    break\n",
    "    \n",
    "for seq, lbl, lengths in test_loader:\n",
    "    seq2, lbl2, lengths2 = seq, lbl, lengths\n",
    "    break\n",
    "    \n",
    "for seq, lbl, lengths in train_loader_nad:\n",
    "    seq1_nad, lbl1_nad, lengths_nad = seq, lbl, lengths\n",
    "    break\n",
    "    \n",
    "for seq, lbl, lengths in test_loader_nad:\n",
    "    seq2_nad, lbl2_nad, lengths2_nad = seq, lbl, lengths\n",
    "    break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4c7ba4-dd2f-4527-bead-0469ca2b5b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert seq1.dtype == torch.int64, \"wrong sequence dtype\"\n",
    "assert lengths1.dtype == torch.int64, \"wrong lenghts dtype\"\n",
    "assert seq1.sum() == seq2.sum(), \"different UNK/data strucutre\"\n",
    "assert lbl1.dtype == torch.float32, \"wrong lbl dtype\"\n",
    "assert (lbl1 == lbl2).sum() == lbl1.shape[0], \"lbl1 and lbl2 are not equal\"\n",
    "assert (lbl1_nad == lbl2_nad).sum() == lbl1.shape[0], \"lbl1_nad and lbl2_nad are not equal\"\n",
    "assert lbl2_nad.dtype == torch.int64, \"nad lbl dtype wrong\"\n",
    "assert lbl1_nad.dtype == torch.int64, \"nad llb dtype wrong\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b925765a-9a1c-4678-9659-01dde18228a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# works for ESM\n",
    "esm2_train = esm2_collator.collate_fn('ESM2BiLSTM', nad=False, train=True, unk_idx=3)\n",
    "esm2_test = esm2_collator.collate_fn('ESM2', nad=False, train=False, unk_idx=3)\n",
    "esm2_train_nad = esm2_collator.collate_fn('ESM2', nad=True, train=True, unk_idx=3)\n",
    "esm2_test_nad = esm2_collator.collate_fn('ESM2BiLSTM', nad=True, train=False, unk_idx=3)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=16, collate_fn=esm2_train, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(train_data, batch_size=16, collate_fn=esm2_test, num_workers=4)\n",
    "train_loader_nad = torch.utils.data.DataLoader(train_data, batch_size=16, collate_fn=esm2_train_nad, num_workers=4)\n",
    "test_loader_nad = torch.utils.data.DataLoader(train_data, batch_size=16, collate_fn=esm2_test_nad, num_workers=4)\n",
    "\n",
    "for seq, lbl in train_loader:\n",
    "    seq1, lbl1 = seq, lbl\n",
    "    break\n",
    "    \n",
    "for seq, lbl in test_loader:\n",
    "    seq2, lbl2 = seq, lbl\n",
    "    break\n",
    "    \n",
    "for seq, lbl in train_loader_nad:\n",
    "    seq1_nad, lbl1_nad = seq, lbl\n",
    "    break\n",
    "    \n",
    "for seq, lbl in test_loader_nad:\n",
    "    seq2_nad, lbl2_nad = seq, lbl\n",
    "    break   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2f984d-8fbf-4726-9f36-1cbefaab4996",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert seq1.dtype == torch.int64, \"wrong sequence dtype\"\n",
    "assert all([3 in s[n] for s in [seq1, seq1_nad] for n in range(s.shape[0])]), \"masking didn't work\"\n",
    "assert not all([3 in s[n] for s in [seq2, seq2_nad] for n in range(s.shape[0])]), \"masking found in test set\"\n",
    "assert lbl1.dtype == torch.float32, \"wrong lbl dtype\"\n",
    "assert (lbl1 == lbl2).sum() == lbl1.shape[0], \"lbl1 and lbl2 are not equal\"\n",
    "assert (lbl1_nad == lbl2_nad).sum() == lbl1.shape[0], \"lbl1_nad and lbl2_nad are not equal\"\n",
    "assert lbl2_nad.dtype == torch.int64, \"nad lbl dtype wrong\"\n",
    "assert lbl1_nad.dtype == torch.int64, \"nad llb dtype wrong\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f921d3-38fa-49c6-8fc1-7b18bc6fd386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# works for T5\n",
    "t5_train = t5_collator.collate_fn('T5BiLSTM', nad=False, train=True, unk_idx=2)\n",
    "t5_test = t5_collator.collate_fn('T5BiLSTM', nad=False, train=False, unk_idx=2)\n",
    "t5_train_nad = t5_collator.collate_fn('T5BiLSTM', nad=True, train=True, unk_idx=2)\n",
    "t5_test_nad = t5_collator.collate_fn('T5BiLSTM', nad=True, train=False, unk_idx=2)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=16, collate_fn=t5_train, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(train_data, batch_size=16, collate_fn=t5_test, num_workers=4)\n",
    "train_loader_nad = torch.utils.data.DataLoader(train_data, batch_size=16, collate_fn=t5_train_nad, num_workers=4)\n",
    "test_loader_nad = torch.utils.data.DataLoader(train_data, batch_size=16, collate_fn=t5_test_nad, num_workers=4)\n",
    "\n",
    "for seq, att, lbl in train_loader:\n",
    "    seq1, att1, lbl1 = seq, att, lbl\n",
    "    break\n",
    "    \n",
    "for seq, att, lbl in test_loader:\n",
    "    seq2, att2, lbl2 = seq, att, lbl\n",
    "    break\n",
    "    \n",
    "for seq, att, lbl in train_loader_nad:\n",
    "    seq1_nad, att1_nad, lbl1_nad = seq, att, lbl\n",
    "    break\n",
    "    \n",
    "for seq, att, lbl in test_loader_nad:\n",
    "    seq2_nad, att2_nad, lbl2_nad = seq, att, lbl\n",
    "    break   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d265fbe-6815-49b4-9346-74f5321a23b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert seq1.dtype == torch.int64, \"wrong sequence dtype\"\n",
    "assert all([2 in s[n] for s in [seq1, seq1_nad] for n in range(s.shape[0])]), \"masking didn't work\"\n",
    "assert not all([2 in s[n] for s in [seq2, seq2_nad] for n in range(s.shape[0])]), \"masking found in test set\"\n",
    "assert lbl1.dtype == torch.float32, \"wrong lbl dtype\"\n",
    "assert (lbl1 == lbl2).sum() == lbl1.shape[0], \"lbl1 and lbl2 are not equal\"\n",
    "assert (lbl1_nad == lbl2_nad).sum() == lbl1.shape[0], \"lbl1_nad and lbl2_nad are not equal\"\n",
    "assert lbl2_nad.dtype == torch.int64, \"nad lbl dtype wrong\"\n",
    "assert lbl1_nad.dtype == torch.int64, \"nad llb dtype wrong\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37727035-fb28-4fe5-ab50-1dc86a132e0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99ec2b8a-7f96-4e5b-997f-68a4a37507c7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e808f41-6a18-4a39-9b17-6abcf85be370",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_base = torch.load('../params/vocab.pt')\n",
    "encode_text = lambda x: vocab_base(list(x))\n",
    "\n",
    "# load pre-trained esm2 model and vocab\n",
    "esm2, vocab = torch.hub.load('facebookresearch/esm:main', 'esm2_t30_150M_UR50D')\n",
    "tokenizer_esm = vocab.get_batch_converter()\n",
    "\n",
    "tokenizer_t5 = T5Tokenizer.from_pretrained(\n",
    "    \"Rostlab/prot_t5_xl_half_uniref50-enc\", do_lower_case=False\n",
    ")\n",
    "\n",
    "# load all tokenizers here\n",
    "bbpe1_vocab, bbpe1_merges = '../params/c_bbpe1k-vocab.json', '../params/c_bbpe1k-merges.txt'\n",
    "bbpe50_vocab, bbpe50_merges = '../params/c_bbpe50k-vocab.json', '../params/c_bbpe50k-merges.txt'\n",
    "wp50_vocab = '../params/c_wp50k-vocab.txt'\n",
    "\n",
    "bbpe1 = ByteLevelBPETokenizer.from_file(bbpe1_vocab, bbpe1_merges, lowercase=False)\n",
    "bbpe1.enable_padding(pad_id=1, pad_token='<PAD>')\n",
    "\n",
    "bbpe50 = ByteLevelBPETokenizer.from_file(bbpe50_vocab, bbpe50_merges, lowercase=False)\n",
    "bbpe50.enable_padding(pad_id=1, pad_token='<PAD>')\n",
    "\n",
    "wp50 = BertWordPieceTokenizer(wp50_vocab)\n",
    "wp50.enable_padding(pad_id=0, pad_token='[PAD]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d262b23a-894b-44e3-a72f-43c5c0afca99",
   "metadata": {},
   "outputs": [],
   "source": [
    "terminus = 'c'\n",
    "\n",
    "train_data = read_data(f\"../data/{terminus}_train.csv\")\n",
    "val_data = read_data(f\"../data/{terminus}_val.csv\")\n",
    "test_data = read_data(f\"../data/{terminus}_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa2ff96-9ea2-448b-8c9a-ea745feb1edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BiLSTM\n",
    "loader = CleavageLoader(train_data, val_data, test_data, encode_text, 16, 4)\n",
    "train_loader, val_loader, test_loader = loader.load('BiLSTMProt2Vec', nad=False, unk_idx=0)\n",
    "train_loader_nad, val_loader_nad, test_loader_nad = loader.load('BiLSTMAttention', nad=True, unk_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a1a690-de69-4a16-94b3-c34d65fd6aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    seq, lbl = batch.seq, batch.lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6686431a-46d9-418f-8cae-e6dd6cf277f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq, lbl in train_loader:\n",
    "    seq1, lbl1 = seq, lbl\n",
    "    break\n",
    "    \n",
    "for seq, lbl in test_loader:\n",
    "    seq2, lbl2 = seq, lbl\n",
    "    break\n",
    "    \n",
    "for seq, lbl in train_loader_nad:\n",
    "    seq1_nad, lbl1_nad = seq, lbl\n",
    "    break\n",
    "    \n",
    "for seq, lbl in test_loader_nad:\n",
    "    seq2_nad, lbl2_nad = seq, lbl\n",
    "    break   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c78fdae-b070-4374-8fbc-9a31679fe25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert seq1.dtype == torch.int64, \"wrong sequence dtype\"\n",
    "assert all([0 in s[n] for s in [seq1, seq1_nad] for n in range(s.shape[0])]), \"masking didn't work\"\n",
    "assert not all([0 in s[n] for s in [seq2, seq2_nad] for n in range(s.shape[0])]), \"masking found in test set\"\n",
    "assert lbl1.dtype == torch.float32, \"wrong lbl dtype\"\n",
    "assert lbl2_nad.dtype == torch.int64, \"nad lbl dtype wrong\"\n",
    "assert lbl1_nad.dtype == torch.int64, \"nad llb dtype wrong\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b930a02-39fc-4ed6-b221-22fcdb5a5596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BBPE50\n",
    "\n",
    "loader = CleavageLoader(train_data, val_data, test_data, bbpe50, 16, 4)\n",
    "train_loader, val_loader, test_loader = loader.load('BiLSTMPadded', nad=False, unk_idx=0)\n",
    "train_loader_nad, val_loader_nad, test_loader_nad = loader.load('BiLSTMPadded', nad=True, unk_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b0a819-4eec-401e-8066-705a6fcf19eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "\n",
    "for seq, lbl, lengths in train_loader:\n",
    "    seq1, lbl1, lengths1 = seq, lbl, lengths\n",
    "    break\n",
    "    \n",
    "for seq, lbl, lengths in test_loader:\n",
    "    seq2, lbl2, lengths2 = seq, lbl, lengths\n",
    "    break\n",
    "    \n",
    "for seq, lbl, lengths in train_loader_nad:\n",
    "    seq1_nad, lbl1_nad, lengths_nad = seq, lbl, lengths\n",
    "    break\n",
    "    \n",
    "for seq, lbl, lengths in test_loader_nad:\n",
    "    seq2_nad, lbl2_nad, lengths2_nad = seq, lbl, lengths\n",
    "    break   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7dd7ca-d82c-42d3-aec0-7fb527c0e339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2751fc41-4b42-4105-9703-00f7d92ef040",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Train/Eval Processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c5d3dd-860b-49c1-9b3d-d1e260008fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dc8b12-3252-4351-9dfd-80bde25a15c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = read_data('../data/c_train.csv')\n",
    "val_data = read_data('../data/c_val.csv')\n",
    "test_data = read_data('../data/c_test.csv')\n",
    "\n",
    "vocab_base = torch.load('../params/vocab.pt')\n",
    "encode_text = lambda x: vocab_base(list(x))\n",
    "\n",
    "# load pre-trained esm2 model and vocab\n",
    "esm2, vocab = torch.hub.load('facebookresearch/esm:main', 'esm2_t30_150M_UR50D')\n",
    "tokenizer_esm = vocab.get_batch_converter()\n",
    "\n",
    "tokenizer_t5 = T5Tokenizer.from_pretrained(\n",
    "    \"Rostlab/prot_t5_xl_half_uniref50-enc\", do_lower_case=False\n",
    ")\n",
    "\n",
    "# load all tokenizers here\n",
    "bbpe1_vocab, bbpe1_merges = '../params/c_bbpe1k-vocab.json', '../params/c_bbpe1k-merges.txt'\n",
    "bbpe50_vocab, bbpe50_merges = '../params/c_bbpe50k-vocab.json', '../params/c_bbpe50k-merges.txt'\n",
    "wp50_vocab = '../params/c_wp50k-vocab.txt'\n",
    "\n",
    "bbpe1 = ByteLevelBPETokenizer.from_file(bbpe1_vocab, bbpe1_merges, lowercase=False)\n",
    "bbpe1.enable_padding(pad_id=1, pad_token='<PAD>')\n",
    "\n",
    "bbpe50 = ByteLevelBPETokenizer.from_file(bbpe50_vocab, bbpe50_merges, lowercase=False)\n",
    "bbpe50.enable_padding(pad_id=1, pad_token='<PAD>')\n",
    "\n",
    "wp50 = BertWordPieceTokenizer.from_file(wp50_vocab, lowercase=False)\n",
    "wp50.enable_padding(pad_id=0, pad_token='[PAD]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc2cc2c-0154-4c22-8c14-a59369e50b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal loader, no padding\n",
    "loader = CleavageLoader(train_data, val_data, test_data, encode_text, 512, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82377a4-53d6-4ce8-86b7-9386dd017ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = loader.load('BiLSTM', nad=False, unk_idx=0)\n",
    "\n",
    "model = BiLSTM(21, 150, 128, 256, 64, 0.5, 1).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "model.train()\n",
    "train_loss, train_acc, train_auc = train_or_eval_base(model, 'BiLSTM', train_loader, criterion, device, optimizer)\n",
    "\n",
    "model.eval()\n",
    "val_loss, val_acc, val_auc = train_or_eval_base(model, 'BiLSTM', val_loader, criterion, device)\n",
    "\n",
    "train_auc, val_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd45c29-251c-45cb-965f-1f464b269b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_nad, val_loader_nad, test_loader_nad = loader.load('BiLSTM', nad=True, unk_idx=0)\n",
    "model_nad = BiLSTM(21, 150, 128, 256, 64, 0.5, 2).to(device)\n",
    "criterion2 = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_nad.parameters(), lr=1e-4)\n",
    "\n",
    "model.train()\n",
    "train_loss, train_acc, train_auc = train_or_eval_nad(model_nad, 'BiLSTM', train_loader_nad, criterion2, device, conf=None, optim=optimizer)\n",
    "\n",
    "model.eval()\n",
    "val_loss, val_acc, val_auc = train_or_eval_nad(model_nad, 'BiLSTM', val_loader_nad, criterion2, device)\n",
    "\n",
    "train_auc, val_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08f9ef7-19a9-4754-8222-661e5ef436b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test padded on nad, normal\n",
    "# padded loader\n",
    "loader = CleavageLoader(train_data, val_data, test_data, bbpe50, 512, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2431d711-e4c2-4f25-937e-c6428a9f3250",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "\n",
    "# normal loading\n",
    "train_loader, val_loader, test_loader = loader.load('Padded', nad=False, unk_idx=0)\n",
    "\n",
    "model = BiLSTMPadded(bbpe50.get_vocab_size(), 150, 128, 256, 64, 0.5, 1, pad_idx=1).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "model.train()\n",
    "train_loss, train_acc, train_auc = train_or_eval_base(model, 'Padded', train_loader, criterion, device, optimizer)\n",
    "\n",
    "model.eval()\n",
    "val_loss, val_acc, val_auc = train_or_eval_base(model, 'Padded', val_loader, criterion, device)\n",
    "\n",
    "train_auc, val_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450fefe3-6926-4429-adb8-2da4a0f903ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nad loading\n",
    "train_loader, val_loader, test_loader = loader.load('Padded', nad=True, unk_idx=0)\n",
    "\n",
    "model = BiLSTMPadded(bbpe50.get_vocab_size(), 150, 128, 256, 64, 0.5, 2, pad_idx=1).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "model.train()\n",
    "train_loss, train_acc, train_auc = train_or_eval_nad(model, 'Padded', train_loader, criterion, device, conf=None, optim=optimizer)\n",
    "\n",
    "model.eval()\n",
    "val_loss, val_acc, val_auc = train_or_eval_nad(model, 'Padded', val_loader, criterion, device)\n",
    "\n",
    "train_auc, val_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2ea1a5-020c-4336-b23f-ac5f6c462087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test esm on nad and normal\n",
    "# esm loader\n",
    "loader = CleavageLoader(train_data, val_data, test_data, tokenizer_esm, 512, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6be045-a74d-4ff1-a4a3-88f401add992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal loading\n",
    "train_loader, val_loader, test_loader = loader.load('ESM2', nad=False, unk_idx=3)\n",
    "\n",
    "model = ESM2(esm2, 0.5, 1).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "model.train()\n",
    "train_loss, train_acc, train_auc = train_or_eval_base(model, 'ESM2', test_loader, criterion, device, optimizer)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    val_loss, val_acc, val_auc = train_or_eval_base(model, 'ESM2', val_loader, criterion, device)\n",
    "\n",
    "train_auc, val_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc206a0-a20d-4dde-80a4-0184269287ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nad loading\n",
    "train_loader, val_loader, test_loader = loader.load('ESM2', nad=True, unk_idx=3)\n",
    "\n",
    "model = ESM2(esm2, 0.5, 2).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "model.train()\n",
    "train_loss, train_acc, train_auc = train_or_eval_nad(model, 'ESM2', test_loader, criterion, device, conf=None, optim=optimizer)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    val_loss, val_acc, val_auc = train_or_eval_nad(model, 'ESM2', val_loader, criterion, device)\n",
    "\n",
    "train_auc, val_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb6f497-6be6-4118-94ba-94ada3e1bcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test t5 on nad and normal\n",
    "loader = CleavageLoader(train_data, val_data, test_data, tokenizer_t5, 512, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d866219-3f51-4a20-bc71-ee807f25aec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale everything to fp16\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# normal loading\n",
    "train_loader, val_loader, test_loader = loader.load('T5', nad=False, unk_idx=2)\n",
    "\n",
    "model = T5BiLSTM(512, 128, 0.5, 1).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "model.train()\n",
    "train_loss, train_acc, train_auc = train_or_eval_base(model, 'T5', train_loader, criterion, device, optimizer, scaler)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    val_loss, val_acc, val_auc = train_or_eval_base(model, 'T5', val_loader, criterion, device, scaler=scaler)\n",
    "\n",
    "train_auc, val_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7d239d-df99-459f-8fe9-1fb005d18814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale everything to fp16\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# normal loading\n",
    "train_loader, val_loader, test_loader = loader.load('T5', nad=True, unk_idx=2)\n",
    "\n",
    "model = T5BiLSTM(512, 128, 0.5, 2).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "model.train()\n",
    "train_loss, train_acc, train_auc = train_or_eval_nad(model, 'T5', test_loader, criterion, device, optim=optimizer, scaler=scaler)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    val_loss, val_acc, val_auc = train_or_eval_nad(model, 'T5', val_loader, criterion, device, scaler=scaler)\n",
    "\n",
    "train_auc, val_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e1554b-500c-4d4c-bbdd-b79c013632f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test everything from above now with coteaching / plus\n",
    "# check print statements especially if correct choice ran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505d7847-3dda-4ff3-b9e4-23ce4d3e86d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BiLSTM\n",
    "loader = CleavageLoader(train_data, val_data, test_data, encode_text, 512, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a4c42f-da55-41b1-a195-96d2489ef740",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# coteaching\n",
    "train_loader, val_loader, test_loader = loader.load('BiLSTM', nad=False, unk_idx=0)\n",
    "\n",
    "model1 = BiLSTM(21, 150, 128, 256, 64, 0.5, 1).to(device)\n",
    "model2 = BiLSTM(21, 150, 128, 256, 64, 0.5, 1).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "cot_criterion = CoteachingLoss()\n",
    "optimizer1 = torch.optim.Adam(model1.parameters(), lr=1e-4)\n",
    "optimizer2 = torch.optim.Adam(model2.parameters(), lr=1e-4)\n",
    "\n",
    "# coteaching training: only cot_criterion!\n",
    "model1.train()\n",
    "model2.train()\n",
    "train_res = train_or_eval_coteaching(\n",
    "    model_name='BiLSTM',\n",
    "    loader=test_loader,\n",
    "    model1=model1,\n",
    "    model2=model2,\n",
    "    device=device,\n",
    "    forget_rate=0.2,\n",
    "    cot_criterion=cot_criterion,\n",
    "    optim1=optimizer1,\n",
    "    optim2=optimizer2,\n",
    ")\n",
    "\n",
    "\n",
    "model1.eval()\n",
    "model2.eval()\n",
    "with torch.no_grad():\n",
    "    val_res = train_or_eval_coteaching(\n",
    "        model_name='BiLSTM',\n",
    "        loader=test_loader,\n",
    "        model1=model1,\n",
    "        model2=model2,\n",
    "        device=device,\n",
    "        forget_rate=0.2,\n",
    "        criterion=criterion,\n",
    "    )\n",
    "\n",
    "train_res, val_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05badf4d-e853-4f1c-9ec8-85b5925d0801",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# coteaching plus\n",
    "train_loader, val_loader, test_loader = loader.load('BiLSTM', nad=False, unk_idx=0)\n",
    "\n",
    "model1 = BiLSTM(21, 150, 128, 256, 64, 0.5, 1).to(device)\n",
    "model2 = BiLSTM(21, 150, 128, 256, 64, 0.5, 1).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "cot_criterion = CoteachingLoss()\n",
    "optimizer1 = torch.optim.Adam(model1.parameters(), lr=1e-4)\n",
    "optimizer2 = torch.optim.Adam(model2.parameters(), lr=1e-4)\n",
    "\n",
    "# coteaching plus training: only cot_criterion!\n",
    "model1.train()\n",
    "model2.train()\n",
    "train_res = train_or_eval_coteaching(\n",
    "    model_name='BiLSTM',\n",
    "    loader=test_loader,\n",
    "    model1=model1,\n",
    "    model2=model2,\n",
    "    device=device,\n",
    "    forget_rate=0.2,\n",
    "    cot_criterion=cot_criterion,\n",
    "    criterion=criterion,\n",
    "    optim1=optimizer1,\n",
    "    optim2=optimizer2,\n",
    "    cot_plus_train=True\n",
    ")\n",
    "\n",
    "\n",
    "model1.eval()\n",
    "model2.eval()\n",
    "with torch.no_grad():\n",
    "    val_res = train_or_eval_coteaching(\n",
    "        model_name='BiLSTM',\n",
    "        loader=test_loader,\n",
    "        model1=model1,\n",
    "        model2=model2,\n",
    "        device=device,\n",
    "        forget_rate=0.2,\n",
    "        criterion=criterion,\n",
    "    )\n",
    "\n",
    "train_res, val_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0415c5cc-429d-42ca-8146-89f3fdfbddfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BBPE50\n",
    "loader = CleavageLoader(train_data, val_data, test_data, wp50, 512, 10)\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d086cc-369b-4811-a40d-bdcb3e60b816",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# coteaching\n",
    "train_loader, val_loader, test_loader = loader.load('Padded', nad=False, unk_idx=1)\n",
    "\n",
    "model1 = BiLSTMPadded(wp50.get_vocab_size(), 150, 128, 256, 64, 0.5, 1, 0).to(device)\n",
    "model2 = BiLSTMPadded(wp50.get_vocab_size(), 150, 128, 256, 64, 0.5, 1, 0).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "cot_criterion = CoteachingLoss()\n",
    "optimizer1 = torch.optim.Adam(model1.parameters(), lr=1e-4)\n",
    "optimizer2 = torch.optim.Adam(model2.parameters(), lr=1e-4)\n",
    "\n",
    "# coteaching training: only cot_criterion!\n",
    "model1.train()\n",
    "model2.train()\n",
    "train_res = train_or_eval_coteaching(\n",
    "    model_name='Padded',\n",
    "    loader=test_loader,\n",
    "    model1=model1,\n",
    "    model2=model2,\n",
    "    device=device,\n",
    "    forget_rate=0.2,\n",
    "    cot_criterion=cot_criterion,\n",
    "    optim1=optimizer1,\n",
    "    optim2=optimizer2,\n",
    ")\n",
    "\n",
    "\n",
    "model1.eval()\n",
    "model2.eval()\n",
    "with torch.no_grad():\n",
    "    val_res = train_or_eval_coteaching(\n",
    "        model_name='Padded',\n",
    "        loader=test_loader,\n",
    "        model1=model1,\n",
    "        model2=model2,\n",
    "        device=device,\n",
    "        forget_rate=0.2,\n",
    "        criterion=criterion,\n",
    "    )\n",
    "\n",
    "train_res, val_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db86420-245d-42df-8ca3-af2abd88310b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# coteaching plus\n",
    "train_loader, val_loader, test_loader = loader.load('Padded', nad=False, unk_idx=1)\n",
    "\n",
    "model1 = BiLSTMPadded(wp50.get_vocab_size(), 150, 128, 256, 64, 0.5, 1, 0).to(device)\n",
    "model2 = BiLSTMPadded(wp50.get_vocab_size(), 150, 128, 256, 64, 0.5, 1, 0).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "cot_criterion = CoteachingLoss()\n",
    "optimizer1 = torch.optim.Adam(model1.parameters(), lr=1e-4)\n",
    "optimizer2 = torch.optim.Adam(model2.parameters(), lr=1e-4)\n",
    "\n",
    "# coteaching plus training: both criterions needed\n",
    "model1.train()\n",
    "model2.train()\n",
    "train_res = train_or_eval_coteaching(\n",
    "    model_name='Padded',\n",
    "    loader=test_loader,\n",
    "    model1=model1,\n",
    "    model2=model2,\n",
    "    device=device,\n",
    "    forget_rate=0.2,\n",
    "    cot_criterion=cot_criterion,\n",
    "    criterion=criterion,\n",
    "    optim1=optimizer1,\n",
    "    optim2=optimizer2,\n",
    "    cot_plus_train=True\n",
    ")\n",
    "\n",
    "\n",
    "model1.eval()\n",
    "model2.eval()\n",
    "with torch.no_grad():\n",
    "    val_res = train_or_eval_coteaching(\n",
    "        model_name='Padded',\n",
    "        loader=test_loader,\n",
    "        model1=model1,\n",
    "        model2=model2,\n",
    "        device=device,\n",
    "        forget_rate=0.2,\n",
    "        criterion=criterion,\n",
    "    )\n",
    "\n",
    "train_res, val_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed634f9-fa9d-4745-962a-db9d79619db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T5\n",
    "loader = CleavageLoader(train_data, val_data, test_data, tokenizer_t5, 512, 10)\n",
    "scaler1 = torch.cuda.amp.GradScaler()\n",
    "scaler2 = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0588893e-2c32-4fb8-bc58-da8383924c99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# coteaching\n",
    "train_loader, val_loader, test_loader = loader.load('T5', nad=False, unk_idx=2)\n",
    "\n",
    "model1 = T5BiLSTM(512, 128, 0.5, 1).to(device)\n",
    "model2 = T5BiLSTM(512, 128, 0.5, 1).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "cot_criterion = CoteachingLoss()\n",
    "optimizer1 = torch.optim.Adam(model1.parameters(), lr=1e-4)\n",
    "optimizer2 = torch.optim.Adam(model2.parameters(), lr=1e-4)\n",
    "\n",
    "# coteaching training: only cot_criterion!\n",
    "model1.train()\n",
    "model2.train()\n",
    "train_res = train_or_eval_coteaching(\n",
    "    model_name='T5',\n",
    "    loader=test_loader,\n",
    "    model1=model1,\n",
    "    model2=model2,\n",
    "    device=device,\n",
    "    forget_rate=0.2,\n",
    "    cot_criterion=cot_criterion,\n",
    "    scaler1=scaler1,\n",
    "    scaler2=scaler2,\n",
    "    optim1=optimizer1,\n",
    "    optim2=optimizer2,\n",
    ")\n",
    "\n",
    "\n",
    "model1.eval()\n",
    "model2.eval()\n",
    "with torch.no_grad():\n",
    "    val_res = train_or_eval_coteaching(\n",
    "        model_name='T5',\n",
    "        loader=test_loader,\n",
    "        model1=model1,\n",
    "        model2=model2,\n",
    "        device=device,\n",
    "        forget_rate=0.2,\n",
    "        criterion=criterion,\n",
    "        scaler1=scaler1,\n",
    "        scaler2=scaler2,\n",
    "    )\n",
    "\n",
    "train_res, val_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8d97d1-1ee3-428f-b6c0-c4b8592ea615",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# coteaching plus\n",
    "train_loader, val_loader, test_loader = loader.load('T5', nad=False, unk_idx=2)\n",
    "\n",
    "model1 = T5BiLSTM(512, 128, 0.5, 1).to(device)\n",
    "model2 = T5BiLSTM(512, 128, 0.5, 1).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "cot_criterion = CoteachingLoss()\n",
    "optimizer1 = torch.optim.Adam(model1.parameters(), lr=1e-4)\n",
    "optimizer2 = torch.optim.Adam(model2.parameters(), lr=1e-4)\n",
    "\n",
    "# coteaching plus training: both criterions\n",
    "model1.train()\n",
    "model2.train()\n",
    "train_res = train_or_eval_coteaching(\n",
    "    model_name='T5',\n",
    "    loader=test_loader,\n",
    "    model1=model1,\n",
    "    model2=model2,\n",
    "    device=device,\n",
    "    forget_rate=0.2,\n",
    "    cot_criterion=cot_criterion,\n",
    "    criterion=criterion,\n",
    "    scaler1=scaler1,\n",
    "    scaler2=scaler2,\n",
    "    optim1=optimizer1,\n",
    "    optim2=optimizer2,\n",
    "    cot_plus_train=True,\n",
    ")\n",
    "\n",
    "\n",
    "model1.eval()\n",
    "model2.eval()\n",
    "with torch.no_grad():\n",
    "    val_res = train_or_eval_coteaching(\n",
    "        model_name='T5',\n",
    "        loader=test_loader,\n",
    "        model1=model1,\n",
    "        model2=model2,\n",
    "        device=device,\n",
    "        forget_rate=0.2,\n",
    "        criterion=criterion,\n",
    "        scaler1=scaler1,\n",
    "        scaler2=scaler2,\n",
    "    )\n",
    "\n",
    "train_res, val_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a2d98e-4efd-4770-9bbd-375b822e7b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jocor\n",
    "# normal tokenizer\n",
    "loader = CleavageLoader(train_data, val_data, test_data, encode_text, 512, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8df655-155b-4b8f-a475-1efd74850825",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = loader.load('BiLSTM', nad=False, unk_idx=0)\n",
    "\n",
    "model1 = BiLSTM(21, 150, 128, 256, 64, 0.5, 1).to(device)\n",
    "model2 = BiLSTM(21, 150, 128, 256, 64, 0.5, 1).to(device)\n",
    "jocor_criterion = JoCoRLoss()\n",
    "optimizer = torch.optim.Adam(list(model1.parameters()) + list(model2.parameters()), lr=1e-4)\n",
    "\n",
    "res_train = train_or_eval_jocor('BiLSTM', train_loader, model1, model2, device, 0.2, jocor_criterion, optim=optimizer)\n",
    "res_val = train_or_eval_jocor('BiLSTM', train_loader, model1, model2, device, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a610f6-0b9c-446c-a89b-61d385436e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "loader = CleavageLoader(train_data, val_data, test_data, bbpe1, 512, 10)\n",
    "\n",
    "train_loader, val_loader, test_loader = loader.load('Padded', nad=False, unk_idx=0)\n",
    "\n",
    "model1 = BiLSTMPadded(bbpe1.get_vocab_size(), 150, 128, 256, 64, 0.5, 1, 1).to(device)\n",
    "model2 = BiLSTMPadded(bbpe1.get_vocab_size(), 150, 128, 256, 64, 0.5, 1, 1).to(device)\n",
    "jocor_criterion = JoCoRLoss()\n",
    "optimizer = torch.optim.Adam(list(model1.parameters()) + list(model2.parameters()), lr=1e-4)\n",
    "\n",
    "res_train = train_or_eval_jocor('Padded', train_loader, model1, model2, device, 0.2, jocor_criterion, optim=optimizer)\n",
    "res_val = train_or_eval_jocor('Padded', train_loader, model1, model2, device, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae589f9-c420-47da-b23d-3a2a84b03515",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = torch.cuda.amp.GradScaler()\n",
    "loader = CleavageLoader(train_data, val_data, test_data, tokenizer_t5, 512, 10)\n",
    "\n",
    "train_loader, val_loader, test_loader = loader.load('T5', nad=False, unk_idx=0)\n",
    "\n",
    "model1 = T5BiLSTM(512, 128, 0.5, 1).to(device)\n",
    "model2 = T5BiLSTM(512, 128, 0.5, 1).to(device)\n",
    "jocor_criterion = JoCoRLoss()\n",
    "optimizer = torch.optim.Adam(list(model1.parameters()) + list(model2.parameters()), lr=1e-4)\n",
    "\n",
    "res_train = train_or_eval_jocor('T5', test_loader, model1, model2, device, 0.2, jocor_criterion, optim=optimizer, scaler=scaler)\n",
    "res_val = train_or_eval_jocor('T5', val_loader, model1, model2, device, 0.2, scaler=scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20812c43-359c-4c55-8144-148b4b00f097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train hybrid test\n",
    "# normal model\n",
    "loader = CleavageLoader(train_data, val_data, test_data, encode_text, 512, 10)\n",
    "\n",
    "train_loader, val_loader, test_loader = loader.load('BiLSTM', nad=True, unk_idx=0)\n",
    "model = BiLSTM(21, 150, 128, 256, 64, 0.5, 2).to(device)\n",
    "\n",
    "conf = torch.tensor([[0.3770, 0.0820], [0.0492, 0.4918]])\n",
    "conf_norm = conf / conf.sum(dim=1, keepdim=True)\n",
    "noisemodel = NoiseAdaptation(theta=conf_norm, k=2, device=device).to(device)\n",
    "noise_optimizer = torch.optim.Adam(noisemodel.parameters(), lr=1e-4)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model.train()\n",
    "noisemodel.train()\n",
    "train_res = train_hybrid_nad('BiLSTM', model, noisemodel, train_loader, optimizer, noise_optimizer, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6718198-ae85-4e6c-924a-09d33006f723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train hybrid test\n",
    "# bbpe\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "loader = CleavageLoader(train_data, val_data, test_data, bbpe50, 512, 10)\n",
    "\n",
    "train_loader, val_loader, test_loader = loader.load('Padded', nad=True, unk_idx=0)\n",
    "model = BiLSTMPadded(bbpe50.get_vocab_size(), 150, 128, 256, 64, 0.5, 2, pad_idx=1).to(device)\n",
    "\n",
    "conf = torch.tensor([[0.3770, 0.0820], [0.0492, 0.4918]])\n",
    "conf_norm = conf / conf.sum(dim=1, keepdim=True)\n",
    "noisemodel = NoiseAdaptation(theta=conf_norm, k=2, device=device).to(device)\n",
    "noise_optimizer = torch.optim.Adam(noisemodel.parameters(), lr=1e-4)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model.train()\n",
    "noisemodel.train()\n",
    "train_res = train_hybrid_nad('Padded', model, noisemodel, train_loader, optimizer, noise_optimizer, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bc7f4e-c9d4-4653-b95a-36340f7a7648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train hybrid test\n",
    "# t5\n",
    "loader = CleavageLoader(train_data, val_data, test_data, tokenizer_t5, 512, 10)\n",
    "\n",
    "train_loader, val_loader, test_loader = loader.load('T5', nad=True, unk_idx=2)\n",
    "model = T5BiLSTM(512, 128, 0.5, 2).to(device)\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "conf = torch.tensor([[0.3770, 0.0820], [0.0492, 0.4918]])\n",
    "conf_norm = conf / conf.sum(dim=1, keepdim=True)\n",
    "noisemodel = NoiseAdaptation(theta=conf_norm, k=2, device=device).to(device)\n",
    "noise_optimizer = torch.optim.Adam(noisemodel.parameters(), lr=1e-4)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model.train()\n",
    "noisemodel.train()\n",
    "train_res = train_hybrid_nad('T5', model, noisemodel, test_loader, optimizer, noise_optimizer, criterion, device, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ec61b1-6c7b-41c2-8ce7-ad5f02fecfd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6298fdf9-c51b-4d6e-8dfa-bf917c0a9f49",
   "metadata": {},
   "source": [
    "# Whole run_train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59258651-511d-4c58-94fa-dc183519380b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5575fec5-00eb-4946-bd2c-5c328beeb9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_val_auc = 0\n",
    "reg_auc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075e34a0-a1b8-4a77-a91e-3baaf1d6fe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if reg_auc <= highest_val_auc:\n",
    "    print('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c90c58-29b3-4858-8e95-13295d6baaf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d94a79-f183-464e-aab7-a897ac3da6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = read_data('../data/c_train.csv')\n",
    "val_data = read_data('../data/c_val.csv')\n",
    "test_data = read_data('../data/c_test.csv')\n",
    "\n",
    "vocab_base = torch.load('../params/vocab.pt')\n",
    "encode_text = lambda x: vocab_base(list(x))\n",
    "\n",
    "# load pre-trained esm2 model and vocab\n",
    "esm2, vocab = torch.hub.load('facebookresearch/esm:main', 'esm2_t30_150M_UR50D')\n",
    "tokenizer_esm = vocab.get_batch_converter()\n",
    "\n",
    "tokenizer_t5 = T5Tokenizer.from_pretrained(\n",
    "    \"Rostlab/prot_t5_xl_half_uniref50-enc\", do_lower_case=False\n",
    ")\n",
    "\n",
    "# load all tokenizers here\n",
    "bbpe1_vocab, bbpe1_merges = '../params/c_bbpe1k-vocab.json', '../params/c_bbpe1k-merges.txt'\n",
    "bbpe50_vocab, bbpe50_merges = '../params/c_bbpe50k-vocab.json', '../params/c_bbpe50k-merges.txt'\n",
    "wp50_vocab = '../params/c_wp50k-vocab.txt'\n",
    "\n",
    "bbpe1 = ByteLevelBPETokenizer.from_file(bbpe1_vocab, bbpe1_merges, lowercase=False)\n",
    "bbpe1.enable_padding(pad_id=1, pad_token='<PAD>')\n",
    "\n",
    "bbpe50 = ByteLevelBPETokenizer.from_file(bbpe50_vocab, bbpe50_merges, lowercase=False)\n",
    "bbpe50.enable_padding(pad_id=1, pad_token='<PAD>')\n",
    "\n",
    "wp50 = BertWordPieceTokenizer(wp50_vocab)\n",
    "wp50.enable_padding(pad_id=0, pad_token='[PAD]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12478ba0-ea20-4166-8a57-841e72ae827e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_schedule = torch.ones(15) * 0.1\n",
    "rate_schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f2646f-5576-49e6-b19b-3a5e497d15af",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_schedule[:10] = torch.linspace(0, 0.1, 10)\n",
    "rate_schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117e8d03-051c-450a-9211-1071d22fe51b",
   "metadata": {},
   "source": [
    "For the main script, we need:\n",
    "* --device\n",
    "* --reading in data\n",
    "    * --with special selection of term\n",
    "* --os.environ\n",
    "* --model loading \n",
    "    * --tokenizer, depending on model choice\n",
    "    * --all hyperparams\n",
    "        * --make the argparse simply take all hyperparams, also those we don't use\n",
    "    * --check especially for unk and pad token indices\n",
    "    * --create dicts with params per each model conf \n",
    "* K-Fold\n",
    "* train loop\n",
    "    * use del for models\n",
    "    * re-create tokenizer per split in train loop, check loops from BBPE re-make\n",
    "    * make paths\n",
    "    * early stopping after 5 epochs overfitting or decreasing val loss\n",
    "    * include print statements for security (check how to not have empty prints when a metric is missing?), maybe just print the result objects\n",
    "    * check how to save results in file with fold and varying numbers of items.\n",
    "        * Check that train and val always return the same number of args, and write util functions to save each kind of denoising technique\n",
    "* somehow save test results too\n",
    "* create option for k-fold or not, if not, it should run base train set and eval on val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15e6fe4-4ed4-4f06-981f-3eec309cbbc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6838e85-683a-46a4-990b-5f7a4eebbba3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
